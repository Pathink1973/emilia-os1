(function(){const e=document.createElement("link").relList;if(e&&e.supports&&e.supports("modulepreload"))return;for(const o of document.querySelectorAll('link[rel="modulepreload"]'))t(o);new MutationObserver(o=>{for(const i of o)if(i.type==="childList")for(const n of i.addedNodes)n.tagName==="LINK"&&n.rel==="modulepreload"&&t(n)}).observe(document,{childList:!0,subtree:!0});function s(o){const i={};return o.integrity&&(i.integrity=o.integrity),o.referrerPolicy&&(i.referrerPolicy=o.referrerPolicy),o.crossOrigin==="use-credentials"?i.credentials="include":o.crossOrigin==="anonymous"?i.credentials="omit":i.credentials="same-origin",i}function t(o){if(o.ep)return;o.ep=!0;const i=s(o);fetch(o.href,i)}})();const m=()=>{const r=[];if(r.push("VITE_OPENAI_API_KEY"),console.error("OpenAI API Key is missing. Please check your Netlify environment variables and ensure VITE_OPENAI_API_KEY is set."),r.push("VITE_ELEVEN_LABS_API_KEY"),console.error("Eleven Labs API Key is missing. Please check your Netlify environment variables and ensure VITE_ELEVEN_LABS_API_KEY is set."),r.push("VITE_ELEVEN_LABS_VOICE_ID"),console.error("Eleven Labs Voice ID is missing. Please check your Netlify environment variables and ensure VITE_ELEVEN_LABS_VOICE_ID is set."),r.length>0){const e=`Missing environment variables: ${r.join(", ")}. Please check your .env file or Netlify environment variables.`;document.querySelector(".status").textContent=e}};m();const d={OPENAI_API_KEY:"",ELEVEN_LABS_API_KEY:"",ELEVEN_LABS_VOICE_ID:"",SYSTEM_PROMPT:`You are Emilia, an empathetic and thoughtful AI assistant. Your responses should be warm, 
                    engaging, and natural. Focus on building a genuine connection with the user while maintaining 
                    a calm and supportive tone. Be concise but meaningful in your responses.`};class g{constructor(e){this.container=e,this.init()}init(){const e=document.createElement("div");e.className="wave-container";for(let s=0;s<3;s++){const t=document.createElement("div");t.className="wave-bar",t.style.animation="waveAnimation 0.8s ease-in-out infinite",t.style.animationDelay=`${s*.15}s`,e.appendChild(t)}this.container.appendChild(e)}}const p=document.getElementById("waveAnimation");p&&new g(p);let l=!1;function u(){if(!l)try{const r=new(window.AudioContext||window.webkitAudioContext),e=r.createBufferSource();e.buffer=r.createBuffer(1,1,22050),e.connect(r.destination),e.start(0),l=!0,setTimeout(()=>r.close(),200),console.log("[Audio] Unlocked audio context")}catch(r){console.warn("[Audio] Unlock failed:",r)}}class E{constructor(){this.micButton=document.getElementById("micButton"),this.status=document.getElementById("status"),this.messagesContainer=document.getElementById("messages"),this.isRecording=!1,this.mediaRecorder=null,this.audioChunks=[],this.silenceTimer=null,this.SILENCE_THRESHOLD=3e3,this.conversationHistory=[{role:"system",content:d.SYSTEM_PROMPT}],this.lastStatusMessage=null,this.initializeEventListeners(),this.checkMicrophonePermissions()}initializeEventListeners(){const e=()=>{u(),window.removeEventListener("touchend",e),window.removeEventListener("click",e)};window.addEventListener("touchend",e),window.addEventListener("click",e),this.micButton.addEventListener("click",()=>{u(),console.log("[Mic] Mic button clicked. isRecording:",this.isRecording),this.isRecording?this.stopRecording():this.startRecording()})}async checkMicrophonePermissions(){try{(await navigator.mediaDevices.getUserMedia({audio:!0})).getTracks().forEach(s=>s.stop()),this.updateStatus("Click the microphone to start")}catch(e){console.error("Microphone permission error:",e),this.updateStatus("Error: Microphone permission denied")}}async startRecording(){try{const e={audio:{echoCancellation:!0,noiseSuppression:!0,autoGainControl:!0,channelCount:1,sampleRate:{ideal:44100}}};if(navigator.mediaDevices.getUserMedia){this.updateStatus("Requesting microphone access..."),console.log("[Mic] Requesting microphone access...");const s=await navigator.mediaDevices.getUserMedia(e),o=new(window.AudioContext||window.webkitAudioContext)().createMediaStreamSource(s);let i="audio/webm;codecs=opus";MediaRecorder.isTypeSupported(i)||(i="audio/mp4"),this.mediaRecorder=new MediaRecorder(s,{mimeType:i}),this.audioChunks=[],this.mediaRecorder.ondataavailable=n=>{n.data.size>0&&(this.audioChunks.push(n.data),console.log("[Mic] Audio chunk received, size:",n.data.size))},this.mediaRecorder.onstart=()=>{this.isRecording=!0,this.micButton.classList.add("active"),this.updateStatus("Listening..."),console.log("[Mic] Recording started."),this.silenceTimer&&clearTimeout(this.silenceTimer),this.silenceTimer=setTimeout(()=>{this.isRecording&&this.stopRecording()},this.SILENCE_THRESHOLD)},this.mediaRecorder.onstop=async()=>{s.getTracks().forEach(a=>a.stop()),console.log("[Mic] Recording stopped. Chunks:",this.audioChunks.length),this.silenceTimer&&clearTimeout(this.silenceTimer),this.audioChunks.length>0?(this.updateStatus("Processing audio..."),await this.processAudio(new Blob(this.audioChunks,{type:i}))):(this.updateStatus("No audio detected. Try again."),console.warn("[Mic] No audio chunks were recorded."))},this.mediaRecorder.start(100)}}catch(e){console.error("Recording error:",e),this.updateStatus("Error: Could not start recording")}}async stopRecording(){this.mediaRecorder&&this.isRecording&&(this.mediaRecorder.stop(),this.isRecording=!1,this.micButton.classList.remove("active"),this.updateStatus("Processing..."))}async processAudio(e){var s;try{this.updateStatus("Converting speech to text..."),console.log("[Whisper] Sending audio to Whisper for transcription.");const t=new FormData;t.append("file",e,"audio.webm"),t.append("model","whisper-1"),t.append("language","en");const o=await fetch("https://api.openai.com/v1/audio/transcriptions",{method:"POST",headers:{Authorization:`Bearer ${d.OPENAI_API_KEY}`},body:t});if(!o.ok){const c=((s=(await o.json().catch(()=>({}))).error)==null?void 0:s.message)||o.statusText;throw this.updateStatus(`Error: ${c}`),console.error("[Whisper] API error:",c),new Error(`Whisper API error: ${o.status} - ${c}`)}const i=await o.json();if(!i.text)throw this.updateStatus("Error: No speech detected"),console.warn("[Whisper] No speech detected in audio."),new Error("No speech detected");const n=i.text.trim();console.log("[Whisper] Transcription result:",n),this.addMessage(n,"user"),this.updateStatus("Emilia is thinking...");const a=await this.getAIResponse(n);this.updateStatus(""),await this.textToSpeech(a)}catch(t){console.error("Audio processing error:",t),this.status.textContent.startsWith("Error:")||this.updateStatus("Error: Failed to process audio. Please try again.")}}addMessage(e,s){const t=document.createElement("div");t.className=`message ${s}`,t.textContent=e,this.messagesContainer.appendChild(t),t.scrollIntoView({behavior:"smooth",block:"end"})}updateStatus(e){this.status.textContent=e,this.lastStatusMessage&&this.lastStatusMessage.remove();const s=document.createElement("div");s.className="message status",s.textContent=e,this.messagesContainer.appendChild(s),this.lastStatusMessage=s,s.scrollIntoView({behavior:"smooth",block:"end"})}async getAIResponse(e){var s;try{if(!d.OPENAI_API_KEY)throw this.updateStatus("Error: OpenAI API Key is not configured"),new Error("OpenAI API Key is not configured");this.conversationHistory.push({role:"user",content:e}),console.log("[GPT] Sending user message to GPT:",e);const t=await fetch("https://api.openai.com/v1/chat/completions",{method:"POST",headers:{Authorization:`Bearer ${d.OPENAI_API_KEY}`,"Content-Type":"application/json"},body:JSON.stringify({model:"gpt-4",messages:this.conversationHistory,temperature:.7,max_tokens:150})});if(!t.ok){const a=((s=(await t.json().catch(()=>({}))).error)==null?void 0:s.message)||t.statusText;throw this.updateStatus(`Error: ${a}`),console.error("[GPT] API error:",a),new Error(`OpenAI API error: ${t.status} - ${a}`)}const o=await t.json();if(!o.choices||!o.choices[0]||!o.choices[0].message)throw this.updateStatus("Error: Invalid response from AI"),console.error("[GPT] Invalid response from OpenAI:",o),new Error("Invalid response from OpenAI");const i=o.choices[0].message.content;return this.conversationHistory.push({role:"assistant",content:i}),console.log("[GPT] AI response:",i),this.addMessage(i,"assistant"),this.updateStatus("Converting response to speech..."),i}catch(t){throw console.error("AI Response error:",t),this.status.textContent.startsWith("Error:")||this.updateStatus("Error: Failed to get AI response. Please try again."),t}}async textToSpeech(e){try{l||u(),console.log("[TTS] Sending text to ElevenLabs:",e);const s=await this.callElevenLabsAPI(e);if(s){let t=!1;const o=new Audio(s);o.onended=()=>{};try{await o.play(),console.log("[Audio] Playback started (Audio element)"),t=!0}catch(i){console.warn("[Audio] play() failed, trying Web Audio API:",i)}if(!t)try{const n=await(await fetch(s)).arrayBuffer(),a=new(window.AudioContext||window.webkitAudioContext),h=await a.decodeAudioData(n),c=a.createBufferSource();c.buffer=h,c.connect(a.destination),c.start(0),c.onended=()=>a.close(),t=!0,console.log("[Audio] Playback started (Web Audio API)")}catch(i){console.error("[Audio] Web Audio API playback failed:",i),this.updateStatus("Tap anywhere to enable sound.")}return t||this.updateStatus("Error: Could not play assistant voice. Tap to retry."),s}else this.updateStatus("Error: No audio URL received from ElevenLabs."),console.error("[TTS] No audio URL received.")}catch(s){throw console.error("Text to speech error:",s),this.updateStatus("Error: Text-to-speech failed."),s}}async callElevenLabsAPI(e){throw this.updateStatus("Error: Eleven Labs credentials are not configured"),console.error("[TTS] Eleven Labs credentials missing."),new Error("Eleven Labs credentials are not configured")}}new E;
