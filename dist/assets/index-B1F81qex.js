(function(){const s=document.createElement("link").relList;if(s&&s.supports&&s.supports("modulepreload"))return;for(const t of document.querySelectorAll('link[rel="modulepreload"]'))o(t);new MutationObserver(t=>{for(const i of t)if(i.type==="childList")for(const a of i.addedNodes)a.tagName==="LINK"&&a.rel==="modulepreload"&&o(a)}).observe(document,{childList:!0,subtree:!0});function e(t){const i={};return t.integrity&&(i.integrity=t.integrity),t.referrerPolicy&&(i.referrerPolicy=t.referrerPolicy),t.crossOrigin==="use-credentials"?i.credentials="include":t.crossOrigin==="anonymous"?i.credentials="omit":i.credentials="same-origin",i}function o(t){if(t.ep)return;t.ep=!0;const i=e(t);fetch(t.href,i)}})();const d={BASE_URL:"/",DEV:!1,MODE:"production",PROD:!0,SSR:!1};var u={};const h=n=>d&&d[n]?d[n]:typeof process<"u"&&u&&u[n]?u[n]:"",r={OPENAI_API_KEY:h("VITE_OPENAI_API_KEY"),ELEVEN_LABS_API_KEY:h("VITE_ELEVEN_LABS_API_KEY"),ELEVEN_LABS_VOICE_ID:h("VITE_ELEVEN_LABS_VOICE_ID"),SYSTEM_PROMPT:`You are Emilia, an empathetic and thoughtful AI assistant. Your responses should be warm, 
                    engaging, and natural. Focus on building a genuine connection with the user while maintaining 
                    a calm and supportive tone. Be concise but meaningful in your responses.`};r.OPENAI_API_KEY||console.error("OpenAI API Key is missing. Please check your Netlify environment variables and ensure VITE_OPENAI_API_KEY is set.");r.ELEVEN_LABS_API_KEY||console.error("Eleven Labs API Key is missing. Please check your Netlify environment variables and ensure VITE_ELEVEN_LABS_API_KEY is set.");r.ELEVEN_LABS_VOICE_ID||console.error("Eleven Labs Voice ID is missing. Please check your Netlify environment variables and ensure VITE_ELEVEN_LABS_VOICE_ID is set.");class m{constructor(){this.micButton=document.getElementById("micButton"),this.status=document.getElementById("status"),this.messagesContainer=document.getElementById("messages"),this.isRecording=!1,this.mediaRecorder=null,this.audioChunks=[],this.silenceTimer=null,this.SILENCE_THRESHOLD=3e3,this.conversationHistory=[{role:"system",content:r.SYSTEM_PROMPT}],this.initializeEventListeners(),this.checkMicrophonePermissions()}initializeEventListeners(){this.micButton.addEventListener("click",()=>this.toggleRecording())}async checkMicrophonePermissions(){try{if(!window.isSecureContext){this.status.textContent="Microphone access requires HTTPS",this.micButton.disabled=!0;return}if(!navigator.mediaDevices||!navigator.mediaDevices.getUserMedia){this.status.textContent="Your browser does not support microphone access",this.micButton.disabled=!0;return}(await navigator.permissions.query({name:"microphone"})).state==="denied"?(this.status.textContent="Microphone access was denied. Please enable it in your browser settings.",this.micButton.disabled=!0):(this.status.textContent="Click the microphone to start",this.micButton.disabled=!1)}catch(s){console.error("Error checking microphone permissions:",s),this.status.textContent="Error checking microphone permissions",this.micButton.disabled=!0}}async toggleRecording(){this.isRecording?await this.stopRecording():await this.startRecording()}async startRecording(){try{const s=await navigator.mediaDevices.getUserMedia({audio:!0});this.mediaRecorder=new MediaRecorder(s),this.audioChunks=[],this.mediaRecorder.ondataavailable=e=>{this.audioChunks.push(e.data)},this.mediaRecorder.onstop=async()=>{const e=new Blob(this.audioChunks,{type:"audio/wav"});await this.processAudio(e)},this.mediaRecorder.start(),this.isRecording=!0,this.micButton.classList.add("active"),this.status.textContent="Listening...",this.startSilenceDetection(s)}catch(s){console.error("Error accessing microphone:",s),s.name==="NotAllowedError"?this.status.textContent="Microphone access denied. Please allow access in your browser settings.":this.status.textContent="Error accessing microphone",this.micButton.disabled=!0,await this.checkMicrophonePermissions()}}async stopRecording(){this.mediaRecorder&&this.isRecording&&(this.mediaRecorder.stop(),this.isRecording=!1,this.micButton.classList.remove("active"),this.status.textContent="Processing...",this.mediaRecorder.stream.getTracks().forEach(s=>s.stop()))}startSilenceDetection(s){const e=new AudioContext,o=e.createMediaStreamSource(s),t=e.createAnalyser();t.fftSize=2048,o.connect(t);const i=t.frequencyBinCount,a=new Uint8Array(i);let c=null;const l=()=>{if(!this.isRecording)return;if(t.getByteFrequencyData(a),a.reduce((p,E)=>p+E)/i<10){if(!c)c=Date.now();else if(Date.now()-c>this.SILENCE_THRESHOLD){this.stopRecording();return}}else c=null;requestAnimationFrame(l)};l()}async processAudio(s){try{const e=await this.getTranscription(s);this.addMessage(e,"user");const o=await this.getAIResponse(e),t=await this.textToSpeech(o);await this.playAudioResponse(t),this.status.textContent="Click the microphone to start"}catch(e){console.error("Error processing audio:",e),this.status.textContent="Error processing audio"}}async getTranscription(s){try{if(!r.OPENAI_API_KEY)throw new Error("OpenAI API Key is not configured");const e=new FormData;e.append("file",s,"audio.wav"),e.append("model","whisper-1");const o=await fetch("https://api.openai.com/v1/audio/transcriptions",{method:"POST",headers:{Authorization:`Bearer ${r.OPENAI_API_KEY}`},body:e});if(!o.ok)throw new Error(`OpenAI API error: ${o.status} ${o.statusText}`);const t=await o.json();if(!t.text)throw new Error("No transcription received from OpenAI");return t.text}catch(e){throw console.error("Transcription error:",e),this.status.textContent="Error: Could not transcribe audio. Please check API keys.",e}}async getAIResponse(s){try{if(!r.OPENAI_API_KEY)throw new Error("OpenAI API Key is not configured");this.conversationHistory.push({role:"user",content:s});const e=await fetch("https://api.openai.com/v1/chat/completions",{method:"POST",headers:{Authorization:`Bearer ${r.OPENAI_API_KEY}`,"Content-Type":"application/json"},body:JSON.stringify({model:"gpt-4",messages:this.conversationHistory,temperature:.7,max_tokens:150})});if(!e.ok)throw new Error(`OpenAI API error: ${e.status} ${e.statusText}`);const o=await e.json();if(!o.choices||!o.choices[0]||!o.choices[0].message)throw new Error("Invalid response from OpenAI");const t=o.choices[0].message.content;return this.conversationHistory.push({role:"assistant",content:t}),this.addMessage(t,"assistant"),t}catch(e){throw console.error("AI Response error:",e),this.status.textContent="Error: Could not get AI response. Please check API keys.",e}}async textToSpeech(s){try{if(!r.ELEVEN_LABS_API_KEY||!r.ELEVEN_LABS_VOICE_ID)throw new Error("Eleven Labs credentials are not configured");const e=await fetch(`https://api.elevenlabs.io/v1/text-to-speech/${r.ELEVEN_LABS_VOICE_ID}`,{method:"POST",headers:{Accept:"audio/mpeg","xi-api-key":r.ELEVEN_LABS_API_KEY,"Content-Type":"application/json"},body:JSON.stringify({text:s,model_id:"eleven_monolingual_v1",voice_settings:{stability:.5,similarity_boost:.5}})});if(!e.ok)throw new Error(`Eleven Labs API error: ${e.status} ${e.statusText}`);const o=await e.blob();return URL.createObjectURL(o)}catch(e){throw console.error("Text-to-speech error:",e),this.status.textContent="Error: Could not convert text to speech. Please check API keys.",e}}async playAudioResponse(s){return new Promise((e,o)=>{const t=new Audio(s);t.onended=e,t.onerror=o,t.play()})}addMessage(s,e){const o=document.createElement("div");o.classList.add("message",e),o.textContent=s,this.messagesContainer.appendChild(o),this.messagesContainer.scrollTop=this.messagesContainer.scrollHeight}}document.addEventListener("DOMContentLoaded",()=>{new m});
