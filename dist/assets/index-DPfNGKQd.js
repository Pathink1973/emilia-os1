(function(){const t=document.createElement("link").relList;if(t&&t.supports&&t.supports("modulepreload"))return;for(const s of document.querySelectorAll('link[rel="modulepreload"]'))i(s);new MutationObserver(s=>{for(const o of s)if(o.type==="childList")for(const a of o.addedNodes)a.tagName==="LINK"&&a.rel==="modulepreload"&&i(a)}).observe(document,{childList:!0,subtree:!0});function e(s){const o={};return s.integrity&&(o.integrity=s.integrity),s.referrerPolicy&&(o.referrerPolicy=s.referrerPolicy),s.crossOrigin==="use-credentials"?o.credentials="include":s.crossOrigin==="anonymous"?o.credentials="omit":o.credentials="same-origin",o}function i(s){if(s.ep)return;s.ep=!0;const o=e(s);fetch(s.href,o)}})();const d={BASE_URL:"/",DEV:!1,MODE:"production",PROD:!0,SSR:!1};var u={};const h=r=>d&&d[r]?d[r]:typeof process<"u"&&u&&u[r]?u[r]:"",n={OPENAI_API_KEY:h("VITE_OPENAI_API_KEY"),ELEVEN_LABS_API_KEY:h("VITE_ELEVEN_LABS_API_KEY"),ELEVEN_LABS_VOICE_ID:h("VITE_ELEVEN_LABS_VOICE_ID"),SYSTEM_PROMPT:`You are Emilia, an empathetic and thoughtful AI assistant. Your responses should be warm, 
                    engaging, and natural. Focus on building a genuine connection with the user while maintaining 
                    a calm and supportive tone. Be concise but meaningful in your responses.`};n.OPENAI_API_KEY||console.error("OpenAI API Key is missing. Please check your Netlify environment variables and ensure VITE_OPENAI_API_KEY is set.");n.ELEVEN_LABS_API_KEY||console.error("Eleven Labs API Key is missing. Please check your Netlify environment variables and ensure VITE_ELEVEN_LABS_API_KEY is set.");n.ELEVEN_LABS_VOICE_ID||console.error("Eleven Labs Voice ID is missing. Please check your Netlify environment variables and ensure VITE_ELEVEN_LABS_VOICE_ID is set.");class E{constructor(){this.micButton=document.getElementById("micButton"),this.status=document.getElementById("status"),this.messagesContainer=document.getElementById("messages"),this.isRecording=!1,this.mediaRecorder=null,this.audioChunks=[],this.silenceTimer=null,this.SILENCE_THRESHOLD=3e3,this.conversationHistory=[{role:"system",content:n.SYSTEM_PROMPT}],this.initializeEventListeners(),this.checkMicrophonePermissions()}initializeEventListeners(){this.micButton.addEventListener("click",()=>this.toggleRecording())}async checkMicrophonePermissions(){try{if(!window.isSecureContext){this.status.textContent="Microphone access requires HTTPS",this.micButton.disabled=!0;return}if(!navigator.mediaDevices||!navigator.mediaDevices.getUserMedia){this.status.textContent="Your browser does not support microphone access",this.micButton.disabled=!0;return}(await navigator.permissions.query({name:"microphone"})).state==="denied"?(this.status.textContent="Microphone access was denied. Please enable it in your browser settings.",this.micButton.disabled=!0):(this.status.textContent="Click the microphone to start",this.micButton.disabled=!1)}catch(t){console.error("Error checking microphone permissions:",t),this.status.textContent="Error checking microphone permissions",this.micButton.disabled=!0}}async toggleRecording(){this.isRecording?await this.stopRecording():await this.startRecording()}async startRecording(){try{const t=await navigator.mediaDevices.getUserMedia({audio:!0});this.mediaRecorder=new MediaRecorder(t),this.audioChunks=[],this.mediaRecorder.ondataavailable=e=>{this.audioChunks.push(e.data)},this.mediaRecorder.onstop=async()=>{const e=new Blob(this.audioChunks,{type:"audio/wav"});await this.processAudio(e)},this.mediaRecorder.start(),this.isRecording=!0,this.micButton.classList.add("active"),this.status.textContent="Listening...",this.startSilenceDetection(t)}catch(t){console.error("Error accessing microphone:",t),t.name==="NotAllowedError"?this.status.textContent="Microphone access denied. Please allow access in your browser settings.":this.status.textContent="Error accessing microphone",this.micButton.disabled=!0,await this.checkMicrophonePermissions()}}async stopRecording(){this.mediaRecorder&&this.isRecording&&(this.mediaRecorder.stop(),this.isRecording=!1,this.micButton.classList.remove("active"),this.status.textContent="Processing...",this.mediaRecorder.stream.getTracks().forEach(t=>t.stop()))}startSilenceDetection(t){const e=new AudioContext,i=e.createMediaStreamSource(t),s=e.createAnalyser();s.fftSize=2048,i.connect(s);const o=s.frequencyBinCount,a=new Uint8Array(o);let c=null;const l=()=>{if(!this.isRecording)return;if(s.getByteFrequencyData(a),a.reduce((p,m)=>p+m)/o<10){if(!c)c=Date.now();else if(Date.now()-c>this.SILENCE_THRESHOLD){this.stopRecording();return}}else c=null;requestAnimationFrame(l)};l()}async processAudio(t){try{const e=await this.getTranscription(t);this.addMessage(e,"user");const i=await this.getAIResponse(e),s=await this.textToSpeech(i);await this.playAudioResponse(s),this.status.textContent="Click the microphone to start"}catch(e){console.error("Error processing audio:",e),this.status.textContent="Error processing audio"}}async getTranscription(t){try{if(!n.OPENAI_API_KEY)throw new Error("OpenAI API Key is not configured");const e=new FormData;e.append("file",t,"audio.wav"),e.append("model","whisper-1");const i=await fetch("https://api.openai.com/v1/audio/transcriptions",{method:"POST",headers:{Authorization:`Bearer ${n.OPENAI_API_KEY}`},body:e});if(!i.ok)throw new Error(`OpenAI API error: ${i.status} ${i.statusText}`);const s=await i.json();if(!s.text)throw new Error("No transcription received from OpenAI");return s.text}catch(e){throw console.error("Transcription error:",e),this.status.textContent="Error: Could not transcribe audio. Please check API keys.",e}}async getAIResponse(t){try{if(!n.OPENAI_API_KEY)throw new Error("OpenAI API Key is not configured");this.conversationHistory.push({role:"user",content:t});const e=await fetch("https://api.openai.com/v1/chat/completions",{method:"POST",headers:{Authorization:`Bearer ${n.OPENAI_API_KEY}`,"Content-Type":"application/json"},body:JSON.stringify({model:"gpt-4",messages:this.conversationHistory,temperature:.7,max_tokens:150})});if(!e.ok)throw new Error(`OpenAI API error: ${e.status} ${e.statusText}`);const i=await e.json();if(!i.choices||!i.choices[0]||!i.choices[0].message)throw new Error("Invalid response from OpenAI");const s=i.choices[0].message.content;return this.conversationHistory.push({role:"assistant",content:s}),this.addMessage(s,"assistant"),s}catch(e){throw console.error("AI Response error:",e),this.status.textContent="Error: Could not get AI response. Please check API keys.",e}}async textToSpeech(t){try{if(!n.ELEVEN_LABS_API_KEY||!n.ELEVEN_LABS_VOICE_ID)throw new Error("Eleven Labs credentials are not configured");const e=await fetch(`https://api.elevenlabs.io/v1/text-to-speech/${n.ELEVEN_LABS_VOICE_ID}`,{method:"POST",headers:{Accept:"audio/mpeg","xi-api-key":n.ELEVEN_LABS_API_KEY,"Content-Type":"application/json"},body:JSON.stringify({text:t,model_id:"eleven_monolingual_v1",voice_settings:{stability:.5,similarity_boost:.5}})});if(!e.ok)throw new Error(`Eleven Labs API error: ${e.status} ${e.statusText}`);const i=await e.blob();return URL.createObjectURL(i)}catch(e){throw console.error("Text-to-speech error:",e),this.status.textContent="Error: Could not convert text to speech. Please check API keys.",e}}async playAudioResponse(t){return new Promise((e,i)=>{const s=new Audio(t);s.onended=e,s.onerror=i,s.play()})}addMessage(t,e){const i=document.createElement("div");i.classList.add("message",e),i.textContent=t,this.messagesContainer.appendChild(i),this.messagesContainer.scrollTop=this.messagesContainer.scrollHeight}}document.addEventListener("DOMContentLoaded",()=>{new E});class g{constructor(){this.dot=document.querySelector(".dot"),this.audio=document.getElementById("soulAudio"),this.isPlaying=!1,this.hasInteracted=!1,this.setupAnimation()}setupAnimation(){document.addEventListener("click",()=>{this.hasInteracted=!0,this.isPlaying||this.playAudio()},{once:!0}),this.dot.addEventListener("animationstart",()=>{!this.isPlaying&&this.hasInteracted&&this.playAudio()}),this.dot.addEventListener("animationiteration",()=>{!this.isPlaying&&this.hasInteracted&&this.playAudio()}),document.addEventListener("visibilitychange",()=>{document.hidden?this.pauseAudio():this.hasInteracted&&this.playAudio()}),this.dot.addEventListener("click",t=>{t.stopPropagation(),this.hasInteracted=!0,this.toggleAudio()}),this.dot.addEventListener("touchend",t=>{t.preventDefault(),t.stopPropagation(),this.hasInteracted=!0,this.toggleAudio()})}async playAudio(){try{this.audio.paused&&this.hasInteracted&&(this.audio.volume=.4,await this.audio.play(),this.isPlaying=!0)}catch{console.log("Waiting for user interaction before playing audio")}}pauseAudio(){this.audio.pause(),this.isPlaying=!1}toggleAudio(){this.isPlaying?this.pauseAudio():this.playAudio()}}document.addEventListener("DOMContentLoaded",()=>{new g});
